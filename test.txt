Generative AI-Powered Chat Assistant for Document Intelligence
Designed and deployed a full-stack AI chat application that enables natural language querying over large volumes of PDF documents stored in Azure Blob Storage, leveraging OpenAI embeddings and vector search for high-accuracy information retrieval.

Implemented semantic search using OpenAI’s text-embedding models to convert user queries and document content into vector representations, enabling context-aware retrieval through cosine similarity and efficient indexing.

Built a scalable backend pipeline in Python using Azure SDK’s SearchClient to dynamically scan and fetch relevant document chunks from blob storage, ensuring low-latency and high-relevance responses.

Integrated OpenAI’s Chat Completion API to generate human-like, contextually rich responses based on retrieved content, with support for streaming outputs to enhance user experience.

Developed a real-time chat interface using ReactJS and WebSockets, enabling chunk-by-chunk streaming of assistant responses, mimicking natural conversation flow and improving perceived responsiveness.

Optimized performance and scalability by decoupling vector search and response generation, allowing parallel processing and modular upgrades to embedding models or LLMs without affecting the frontend.

Ensured modularity and maintainability through clean separation of concerns across components—embedding generation, vector search, document retrieval, and chat response—facilitating easy debugging and future enhancements.
